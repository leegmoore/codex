===== PHASE 3.5: CODER PROMPT =====
ROLE: Senior TypeScript developer implementing phases of the Cody CLI integration project. You write clean, tested code following TDD principles with mocked-service tests at library boundaries.


---

PRODUCT:

**Cody** is a command-line interface for the Codex TypeScript library. It provides multi-provider LLM agent capabilities supporting OpenAI (Responses, Chat) and Anthropic (Messages) APIs with tool execution, conversation persistence, and structured tool calling. Built as a TypeScript port of OpenAI's Rust-based Codex CLI, Cody serves as both a standalone CLI tool and reference implementation for the @openai/codex-core library.


---

PROJECT CONTEXT:

# Project 02: UI Integration & Library Definition

## What We're Building

Project 02 integrates all ported Codex modules (Phases 1-6) into a working command-line interface called **Cody** and defines the library API surface for @openai/codex-core. This project validates the Rust → TypeScript port by wiring protocol, configuration, persistence, execution, client, tools, and orchestration layers into complete conversation flows.

## Why It Matters

The port is functionally complete but untested as an integrated system. Individual modules have unit tests, but we haven't verified end-to-end workflows. This project proves the port works, exposes integration issues, and establishes the library interface that external developers will use.

## Project Success Criteria

By project completion:
- User can create conversations, send messages, receive responses (all providers: OpenAI Responses/Chat, Anthropic Messages)
- All auth methods work (API keys, ChatGPT OAuth, Claude OAuth)
- Tools execute with approval flow
- Conversations persist and resume (JSONL format)
- MCP integration functional
- Library API documented (public exports, usage examples)
- REST API designed (optional implementation)
- Zero-error quality baseline maintained (0 TS errors, 0 ESLint errors, all tests passing)

## Dependencies

- Phase 6 complete (75 modules ported, 1,876 tests passing)
- Phase 5.2 complete (quality baseline clean)
- API keys: OpenAI, Anthropic, OpenRouter
- OAuth tokens: Read from ~/.codex (ChatGPT), ~/.claude (Claude)

## Scope

**In scope:** CLI commands, provider integration (3 APIs), auth methods (4 total), tool execution, persistence/resume, library API docs, REST API spec

**Non-scope:** Script harness (Project 03), memory innovations (Projects 04-06), rich TUI, additional tools, performance optimization, production hardening


---

PHASE 3.5 TECHNICAL DESIGN:

# Phase 3.5 (Optional): Gemini Support

**Goal:** Add Google Gemini client support (streaming + grounding) as an optional provider that can be enabled once Gemini 3.0 is available. Mirrors existing provider flow while using `@google/generative-ai` SDK.

---

## API Client

```typescript
import {GoogleGenerativeAI, GenerativeModel} from '@google/generative-ai';

class GeminiClient implements ModelClient {
  private model: GenerativeModel;

  constructor(private params: {model: string; apiKey: string; grounding?: boolean}) {
    const genAI = new GoogleGenerativeAI(params.apiKey);
    this.model = genAI.getGenerativeModel({model: params.model});
  }

  async sendMessage(request: ModelRequest): Promise<ModelResponse> {
    const {messages} = request;
    const response = await this.model.generateContent({
      contents: convertToGemini(messages),
      tools: this.params.grounding ? [{googleSearch: {}}] : undefined,
      generationConfig: {temperature: request.temperature, topP: request.topP}
    });
    return convertFromGemini(response);
  }
}
```

Need adapters `convertToGemini` / `convertFromGemini` similar to Messages adapter.

---

## Provider Configuration

Config addition:
```toml
[provider]
name = "gemini"
api = "generateContent"
model = "gemini-2.5-pro"

[auth]
gemini_api_key = "..."
```

CLI `set-provider gemini --api generateContent --model gemini-2.5-pro`.

---

## Grounding Toggle

Allow user flag `--grounding` to enable Google Search grounding (cost $35/1k prompts). Config entry `[gemini] grounding = true`.

---

## Auth

`AuthManager.getToken('gemini')` returns API key from config/env. Add validation.

---

## Testing Strategy

- Mock `@google/generative-ai` module returning stub responses.
- Verify factory selects GeminiClient when provider=gemini.
- Ensure ResponseItems parity with other providers.

---

## Manual Enablement Notes

Only wire this phase when Gemini 3.x stable. Document toggle in README.


---

TEST CONDITIONS:

# Phase 3.5 Test Conditions

1. **Factory Selects GeminiClient** – provider=gemini yields GeminiClient instance.
2. **sendMessage Converts History** – ensure convertToGemini called with correct contents.
3. **Grounding Flag** – when config.gemini.grounding = true, request includes `tools: [{googleSearch:{}}]`.
4. **Response Conversion** – convertFromGemini maps Gemini candidates to ResponseItems.
5. **Missing API Key** – errors clearly instruct user to set GCP key.


---

TASKS (update source/checklist.md as you work):

# Phase 3.5 Checklist – Gemini (Optional)

- [ ] Add provider enum entry `gemini`
- [ ] Extend config schema for Gemini settings (model, grounding)
- [ ] Add AuthManager support for `gemini_api_key`
- [ ] Implement GeminiClient adapter using @google/generative-ai
- [ ] Update CLI `list-providers` to show Gemini
- [ ] Add tests from test-conditions.md
- [ ] Document activation steps in README


---

STANDARDS:

See docs/core/dev-standards.md for complete coding standards.
See docs/core/contract-testing-tdd-philosophy.md for testing approach.

Key requirements:
- TypeScript strict mode, no any types
- ESLint 0 errors
- Prettier formatted
- Mocked-service tests at library boundaries
- Mock all external dependencies


---

EXECUTION WORKFLOW:

EXECUTION WORKFLOW:

1. Read all reference documents (project context, phase design, standards, test conditions)
2. Review checklist (understand all tasks)
3. Write mocked-service tests FIRST (TDD):
   - Create test file based on test-conditions.md
   - Implement mocks (ModelClient, Config, etc.)
   - Write tests for each functional condition
   - Run tests (should fail - nothing implemented)
4. Implement code to pass tests:
   - Create files listed in checklist
   - Follow design.md implementation specifics
   - Run tests after each component
   - Iterate until all tests green
5. Manual functional testing:
   - Follow manual-test-script.md
   - Execute each test case
   - Verify expected behavior
   - Document any issues
6. Quality verification:
   - Run: npm run format (fix formatting)
   - Run: npm run lint (fix errors)
   - Run: npx tsc --noEmit (fix type errors)
   - Run: npm test (verify all pass)
   - Run combined: npm run format && npm run lint && npx tsc --noEmit && npm test
   - All must pass before proceeding
7. Update artifacts:
   - Update checklist.md (check off completed tasks)
   - Update decisions.md (log implementation choices with rationale)
8. Final verification:
   - All checklist items checked
   - All quality gates pass
   - Manual tests successful
   - Decisions documented
9. Commit and push
10. Report completion, ready for quality verifier and code reviewer

DO NOT declare phase complete until all steps verified.


---

MANUAL VERIFICATION:

# Phase 3.5 Manual Steps (when Gemini enabled)

1. Obtain Gemini API key (`GEMINI_API_KEY`).
2. `cody set-provider gemini --api generateContent --model gemini-2.5-pro`
3. `cody chat "Summarize today's plan"`
4. Toggle grounding: `cody config set gemini.grounding true` (or edit config), re-run chat, ensure response cites sources.


---

FINAL QUALITY CHECK:

Before declaring phase complete:

Run: npm run format && npm run lint && npx tsc --noEmit && npm test

ALL must pass. Document results.
Update checklist.md and decisions.md.
Commit and push.
Ready for verification stages.

===== END CODER PROMPT =====
